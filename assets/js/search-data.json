{
  
    
        "post0": {
            "title": "COVID-19 Deaths Per Capita",
            "content": "Deaths Per Million Of Inhabitants . Since reaching at least 1 death per million . Tip: Click (Shift+ for multiple) on countries in the legend to filter the visualization. . Last Available Total Deaths By Country: . date Deaths per Million Log of Deaths per Million . Country . China 2020-03-20 | 2.307882 | 0.363214 | . France 2020-03-20 | 6.693804 | 0.825673 | . Iran 2020-03-20 | 17.655874 | 1.246889 | . Italy 2020-03-20 | 67.924641 | 1.832027 | . South Korea 2020-03-20 | 1.843780 | 0.265709 | . Spain 2020-03-20 | 22.500599 | 1.352194 | . United Kingdom 2020-03-20 | 2.689570 | 0.429683 | . Appendix . . Warning: The following chart, &quot;Cases Per Million of Habitants&quot; is biased depending on how widely a country administers tests. Please read with caution. . Cases Per Million of Habitants . date Cases per Million Log of Cases per Million . Country . Brazil 2020-03-20 | 3.789032 | 0.578528 | . China 2020-03-20 | 57.643841 | 1.760753 | . France 2020-03-20 | 189.300776 | 2.277152 | . Germany 2020-03-20 | 241.712072 | 2.383298 | . Iran 2020-03-20 | 242.032099 | 2.383873 | . Italy 2020-03-20 | 792.134065 | 2.898799 | . Japan 2020-03-20 | 7.553862 | 0.878169 | . Portugal 2020-03-20 | 98.746253 | 1.994521 | . Singapore 2020-03-20 | 67.439220 | 1.828913 | . South Korea 2020-03-20 | 169.706249 | 2.229698 | . Spain 2020-03-20 | 440.304157 | 2.643753 | . United Kingdom 2020-03-20 | 60.651311 | 1.782840 | . United States 2020-03-20 | 58.867136 | 1.769873 | . This analysis was conducted by Joao B. Duarte. Assitance with creating visualizations were provided by Hamel Husain. Relevant sources are listed below: . &quot;2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by Johns Hopkins CSSE&quot; GitHub repository. . | Feenstra, Robert C., Robert Inklaar and Marcel P. Timmer (2015), &quot;The Next Generation of the Penn World Table&quot; American Economic Review, 105(10), 3150-3182 . |",
            "url": "https://fabsta.github.io/fabsta.github.io/covid-compare-permillion/",
            "relUrl": "/covid-compare-permillion/",
            "date": " • Mar 19, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "import autogluon as ag from autogluon import TabularPrediction as task . train_data = task.Dataset(file_path=&#39;https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv&#39;) train_data = train_data.head(500) # subsample 500 data points for faster demo print(train_data.head()) . Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -&gt; 39073 . age workclass fnlwgt education education-num marital-status 0 25 Private 178478 Bachelors 13 Never-married 1 23 State-gov 61743 5th-6th 3 Never-married 2 46 Private 376789 HS-grad 9 Never-married 3 55 ? 200235 HS-grad 9 Married-civ-spouse 4 36 Private 224541 7th-8th 4 Married-civ-spouse occupation relationship race sex capital-gain 0 Tech-support Own-child White Female 0 1 Transport-moving Not-in-family White Male 0 2 Other-service Not-in-family White Male 0 3 ? Husband White Male 0 4 Handlers-cleaners Husband White Male 0 capital-loss hours-per-week native-country class 0 0 40 United-States &lt;=50K 1 0 35 United-States &lt;=50K 2 0 15 United-States &lt;=50K 3 0 50 United-States &gt;50K 4 0 40 El-Salvador &lt;=50K . label_column = &#39;class&#39; print(&quot;Summary of class variable: n&quot;, train_data[label_column].describe()) . Summary of class variable: count 500 unique 2 top &lt;=50K freq 394 Name: class, dtype: object . dir = &#39;agModels-predictClass&#39; # specifies folder where to store trained models predictor = task.fit(train_data=train_data, label=label_column, output_directory=dir) . Beginning AutoGluon training ... Preprocessing data ... Here are the first 10 unique label values in your data: [&#39; &lt;=50K&#39; &#39; &gt;50K&#39;] AutoGluon infers your prediction problem is: binary (because only two unique label-values observed) If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: [&#39;binary&#39;, &#39;multiclass&#39;, &#39;regression&#39;]) Selected class &lt;--&gt; label mapping: class 1 = &gt;50K, class 0 = &lt;=50K Data preprocessing and feature engineering runtime = 0.16s ... AutoGluon will gauge predictive performance using evaluation metric: accuracy To change this, specify the eval_metric argument of fit() /usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/imp.py:342: DeprecationWarning: Using or importing the ABCs from &#39;collections&#39; instead of from &#39;collections.abc&#39; is deprecated, and in 3.8 it will stop working return _load(spec) Fitting model: RandomForestClassifierGini ... 0.69s = Training runtime 0.9 = Validation accuracy score Fitting model: RandomForestClassifierEntr ... 0.7s = Training runtime 0.9 = Validation accuracy score Fitting model: ExtraTreesClassifierGini ... 0.51s = Training runtime 0.87 = Validation accuracy score Fitting model: ExtraTreesClassifierEntr ... 0.48s = Training runtime 0.86 = Validation accuracy score Fitting model: KNeighborsClassifierUnif ... 0.02s = Training runtime 0.8 = Validation accuracy score Fitting model: KNeighborsClassifierDist ... 0.01s = Training runtime 0.77 = Validation accuracy score Fitting model: LightGBMClassifier ... 0.74s = Training runtime 0.88 = Validation accuracy score Fitting model: CatboostClassifier ... 1.11s = Training runtime 0.9 = Validation accuracy score Fitting model: NeuralNetClassifier ... 7.53s = Training runtime 0.87 = Validation accuracy score Fitting model: LightGBMClassifierCustom ... 1.13s = Training runtime 0.89 = Validation accuracy score Fitting model: weighted_ensemble_l1 ... 0.59s = Training runtime 0.9 = Validation accuracy score AutoGluon training complete, total runtime = 16.0s ... . test_data = task.Dataset(file_path=&#39;https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv&#39;) y_test = test_data[label_column] # values to predict test_data_nolab = test_data.drop(labels=[label_column],axis=1) # delete label column to prove we&#39;re not cheating print(test_data_nolab.head()) . Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -&gt; 9769 . age workclass fnlwgt education education-num 0 31 Private 169085 11th 7 1 17 Self-emp-not-inc 226203 12th 8 2 47 Private 54260 Assoc-voc 11 3 21 Private 176262 Some-college 10 4 17 Private 241185 12th 8 marital-status occupation relationship race sex 0 Married-civ-spouse Sales Wife White Female 1 Never-married Sales Own-child White Male 2 Married-civ-spouse Exec-managerial Husband White Male 3 Never-married Exec-managerial Own-child White Female 4 Never-married Prof-specialty Own-child White Male capital-gain capital-loss hours-per-week native-country 0 0 0 20 United-States 1 0 0 45 United-States 2 0 1887 60 United-States 3 0 0 30 United-States 4 0 0 20 United-States . predictor = task.load(dir) # unnecessary, just demonstrates how to load previously-trained predictor from file y_pred = predictor.predict(test_data_nolab) print(&quot;Predictions: &quot;, y_pred) perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True) . Evaluation: accuracy on test data: 0.824854 Evaluations on test data: { &#34;accuracy&#34;: 0.8248541304125294, &#34;accuracy_score&#34;: 0.8248541304125294, &#34;balanced_accuracy_score&#34;: 0.7104318244165013, &#34;matthews_corrcoef&#34;: 0.47480025693977573, &#34;f1_score&#34;: 0.8248541304125294 } . Predictions: [&#39; &lt;=50K&#39; &#39; &lt;=50K&#39; &#39; &lt;=50K&#39; ... &#39; &lt;=50K&#39; &#39; &lt;=50K&#39; &#39; &lt;=50K&#39;] . Detailed (per-class) classification report: { &#34; &lt;=50K&#34;: { &#34;precision&#34;: 0.8546712802768166, &#34;recall&#34;: 0.928197557374849, &#34;f1-score&#34;: 0.8899182911921766, &#34;support&#34;: 7451 }, &#34; &gt;50K&#34;: { &#34;precision&#34;: 0.6809779367918902, &#34;recall&#34;: 0.4926660914581536, &#34;f1-score&#34;: 0.5717146433041302, &#34;support&#34;: 2318 }, &#34;accuracy&#34;: 0.8248541304125294, &#34;macro avg&#34;: { &#34;precision&#34;: 0.7678246085343534, &#34;recall&#34;: 0.7104318244165013, &#34;f1-score&#34;: 0.7308164672481534, &#34;support&#34;: 9769 }, &#34;weighted avg&#34;: { &#34;precision&#34;: 0.8134571160636874, &#34;recall&#34;: 0.8248541304125294, &#34;f1-score&#34;: 0.8144145491710391, &#34;support&#34;: 9769 } } .",
            "url": "https://fabsta.github.io/fabsta.github.io/2020/02/25/Untitled.html",
            "relUrl": "/2020/02/25/Untitled.html",
            "date": " • Feb 25, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc: true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://fabsta.github.io/fabsta.github.io/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Footnotes . This is the footnote. &#8617; . |",
            "url": "https://fabsta.github.io/fabsta.github.io/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://fabsta.github.io/fabsta.github.io/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}